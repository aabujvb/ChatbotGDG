{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "c134b93c-4ba0-444c-8d79-5e790bfafa44",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "#os.environ[\"KMP_DUPLICATE_LIB_OK\"] = \"TRUE\"\n",
    "from sklearn.neighbors import NearestNeighbors\n",
    "from transformers import AutoTokenizer, AutoModel\n",
    "import torch\n",
    "torch.set_num_threads(1)\n",
    "#import faiss\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "5043dbe4-a182-4c34-946a-e0f436a2d8b6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdin",
     "output_type": "stream",
     "text": [
      "Enter your query:  How do I solve problem C from Contest#792?\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "System: I am solving a Competitive Programming problem, and I need help understanding its editorial.\n",
      "Answer my questions regarding the editorial.\n",
      "Let me know if I'm misunderstanding anything.\n",
      "Do not write or debug code.\n",
      "\n",
      "Context 1: Gmail was in beta for 5 years. Â What's the rush?\n",
      "Context 2: Hmm... Codeforces is not beta anymore. May the picture be changed?\n",
      "Context 3: Have you yourself written translation of this entry into English?\n",
      "Context 4: Why doesnt this post have any upvote or downvote @@\n",
      "Context 5: Hi. Though I don't take this blog a proper place for making new friends...\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "#os.environ[\"KMP_DUPLICATE_LIB_OK\"] = \"TRUE\"\n",
    "from sklearn.neighbors import NearestNeighbors\n",
    "from transformers import AutoTokenizer, AutoModel\n",
    "import torch\n",
    "torch.set_num_threads(1)\n",
    "#import faiss\n",
    "import numpy as np\n",
    "\n",
    "def load_markdown_file(file_path):\n",
    "    with open(file_path, 'r', encoding='utf-8') as file:\n",
    "        return file.read()\n",
    "\n",
    "# 3.1 Embedding Generation\n",
    "class CodeBERTEmbedder:\n",
    "    def __init__(self, model_name='microsoft/codebert-base'):\n",
    "        self.tokenizer = AutoTokenizer.from_pretrained(model_name)\n",
    "        self.model = AutoModel.from_pretrained(model_name)\n",
    "\n",
    "    def generate_embedding(self, text):\n",
    "        tokens = self.tokenizer(text, return_tensors='pt', truncation=True, padding=True)\n",
    "        with torch.no_grad():\n",
    "            outputs = self.model(**tokens)\n",
    "        embedding = outputs.last_hidden_state.mean(dim=1).squeeze()\n",
    "        return embedding.numpy()\n",
    "\n",
    "    def batch_generate_embeddings(self, texts, batch_size=2):\n",
    "        all_embeddings = []\n",
    "        for i in range(0, len(texts), batch_size):\n",
    "            batch = texts[i:i + batch_size]\n",
    "            tokens = self.tokenizer(batch, return_tensors='pt', truncation=True, padding=True, max_length=128)\n",
    "            with torch.no_grad():\n",
    "                outputs = self.model(**tokens)\n",
    "            embeddings = outputs.last_hidden_state.mean(dim=1).numpy()\n",
    "            all_embeddings.append(embeddings)\n",
    "        return np.vstack(all_embeddings)\n",
    "\n",
    "# 3.2 Vector Store Implementation\n",
    "\n",
    "class VectorStore:\n",
    "    def __init__(self, dim=768):\n",
    "        self.data = []\n",
    "        self.texts = []\n",
    "\n",
    "    def add_embeddings(self, texts, embeddings):\n",
    "        self.data = embeddings\n",
    "        self.texts = texts\n",
    "        self.nn = NearestNeighbors(n_neighbors=5, metric='cosine').fit(embeddings)\n",
    "\n",
    "    def search(self, query_embedding, k=5):\n",
    "        distances, indices = self.nn.kneighbors([query_embedding], n_neighbors=k)\n",
    "        results = [(self.texts[idx], 1 - distances[0][i]) for i, idx in enumerate(indices[0])]\n",
    "        return results\n",
    "\n",
    "'''class VectorStore:\n",
    "    def __init__(self, dim=768, index_type='flat_l2'):\n",
    "        if index_type == 'flat_ip':\n",
    "            self.index = faiss.IndexFlatIP(dim)\n",
    "        elif index_type == 'flat_l2':\n",
    "            self.index = faiss.IndexFlatL2(dim)\n",
    "        else:\n",
    "            raise ValueError(\"Unsupported index type\")\n",
    "        self.id_to_text = {}\n",
    "\n",
    "    def add_embeddings(self, texts, embeddings):\n",
    "        if isinstance(embeddings, torch.Tensor):\n",
    "            embeddings = embeddings.detach().numpy()\n",
    "        self.index.add(embeddings)\n",
    "        for idx, text in enumerate(texts):\n",
    "            self.id_to_text[len(self.id_to_text)] = text\n",
    "\n",
    "    def search(self, query_embedding, k=5):\n",
    "        if isinstance(query_embedding, torch.Tensor):\n",
    "            query_embedding = query_embedding.detach().numpy()\n",
    "        if len(query_embedding.shape) == 1:\n",
    "           query_embedding = query_embedding.reshape(1, -1)  # Ensure 2D array\n",
    "           distances, indices = self.index.search(query_embedding, k)\n",
    "           results = [(self.id_to_text[idx], distances[0][i]) for i, idx in enumerate(indices[0])]\n",
    "           return results'''\n",
    "\n",
    "\n",
    "# 3.3 RAG Implementation\n",
    "class RAGRetriever:\n",
    "    def __init__(self, embedder, vector_store):\n",
    "        self.embedder = embedder\n",
    "        self.vector_store = vector_store\n",
    "\n",
    "    def retrieve_context(self, query, top_k=5):\n",
    "        query_embedding = self.embedder.generate_embedding(query)\n",
    "        results = self.vector_store.search(query_embedding, k=top_k)\n",
    "        return results\n",
    "\n",
    "# 3.4 Chatbot Integration\n",
    "class CPChatbot:\n",
    "    def __init__(self, retriever, system_message):\n",
    "        self.retriever = retriever\n",
    "        self.system_message = system_message\n",
    "\n",
    "    def chat(self, user_query):\n",
    "        contexts = self.retriever.retrieve_context(user_query)\n",
    "        response = f\"System: {self.system_message}\\n\\n\"\n",
    "        response += \"\\n\".join([f\"Context {i+1}: {context}\" for i, (context, _) in enumerate(contexts)])\n",
    "        return response\n",
    "\n",
    "# 4 Example Usage\n",
    "if __name__ == \"__main__\":\n",
    "    # Initialize components\n",
    "    embedder = CodeBERTEmbedder()\n",
    "    vector_store = VectorStore()\n",
    "    retriever = RAGRetriever(embedder, vector_store)\n",
    "\n",
    "    # Load Markdown file and split it into lines or paragraphs\n",
    "    file_path = \"C:/Users/91902/Desktop/combined.md\"\n",
    "    markdown_content = load_markdown_file(file_path)\n",
    "    documents = [doc.strip() for doc in markdown_content.split(\"\\n\") if doc.strip()]\n",
    "\n",
    "    # Add data from the Markdown file\n",
    "    embeddings = embedder.batch_generate_embeddings(documents)\n",
    "    vector_store.add_embeddings(documents, embeddings)\n",
    "\n",
    "    # Create chatbot\n",
    "    system_message = (\n",
    "        \"I am solving a Competitive Programming problem, and I need help understanding its editorial.\\n\"\n",
    "        \"Answer my questions regarding the editorial.\\n\"\n",
    "        \"Let me know if I'm misunderstanding anything.\\n\"\n",
    "        \"Do not write or debug code.\"\n",
    "    )\n",
    "    chatbot = CPChatbot(retriever, system_message)\n",
    "\n",
    "    # Chat example\n",
    "    user_query = input(\"Enter your query: \")  # Accept user input dynamically\n",
    "    print(chatbot.chat(user_query))\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "34e897a1-44ea-4f8c-a20f-9fe35b46e473",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
